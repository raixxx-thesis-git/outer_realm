{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "LBSAEQcR02ol"
      ],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# For Developer Only!"
      ],
      "metadata": {
        "id": "LBSAEQcR02ol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Once\n",
        "!git clone https://github.com/raixxx-thesis-git/outer_realm --branch dev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6gmjbMt1JOH",
        "outputId": "b1e37ebb-ee6f-45f2-86a3-c70ca6576cb2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'outer_realm'...\n",
            "remote: Enumerating objects: 177, done.\u001b[K\n",
            "remote: Counting objects: 100% (177/177), done.\u001b[K\n",
            "remote: Compressing objects: 100% (119/119), done.\u001b[K\n",
            "remote: Total 177 (delta 105), reused 124 (delta 52), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (177/177), 31.05 KiB | 1.63 MiB/s, done.\n",
            "Resolving deltas: 100% (105/105), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import outer_realm as otr\n",
        "import shutil\n",
        "import sys"
      ],
      "metadata": {
        "id": "edW-kzMWZcwc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def otr_update(otr):\n",
        "  pending_for_deletion = []\n",
        "  for i in sys.modules:\n",
        "    if i.split('.')[0] == 'outer_realm':\n",
        "      pending_for_deletion.append(i)\n",
        "\n",
        "  for i in pending_for_deletion:\n",
        "    del sys.modules[i]\n",
        "\n",
        "  import outer_realm as otr\n",
        "  return otr"
      ],
      "metadata": {
        "id": "fN9rjksbZd-k"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run to update\n",
        "%cd outer_realm\n",
        "!git stash\n",
        "!git fetch --all\n",
        "!git pull\n",
        "!git checkout dev\n",
        "%cd ..\n",
        "\n",
        "otr = otr_update(otr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DX97tmFU-BBg",
        "outputId": "8eba77b7-e498-47f7-d94c-14283a41dc1d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/outer_realm\n",
            "Saved working directory and index state WIP on dev: 6ff38ef debug\n",
            "Fetching origin\n",
            "Already up to date.\n",
            "Already on 'dev'\n",
            "Your branch is up to date with 'origin/dev'.\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf train_dataset\n",
        "!rm -rf val_dataset"
      ],
      "metadata": {
        "id": "ZOCaqHv01ffv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "location_template = 'drive/MyDrive/thesis/tfrecords_stalta_threadX(coreY)'\n",
        "\n",
        "def get_copy_paths(copy_codes):\n",
        "  copy_paths = []\n",
        "  for copy_code in copy_codes:\n",
        "    target_location = location_template.replace('X', copy_code[0]).replace('Y', copy_code[1])\n",
        "    copy_paths.append(target_location)\n",
        "  return copy_paths\n",
        "\n",
        "copy_codes = ['00', '01', '02']\n",
        "train_dataset_to_copy_paths = get_copy_paths(copy_codes)\n",
        "\n",
        "copy_codes = ['10', '11', '12']\n",
        "val_dataset_to_copy_paths = get_copy_paths(copy_codes)\n",
        ""
      ],
      "metadata": {
        "id": "CFj8c58Y2ogG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.copytree(train_dataset_to_copy_paths[0], 'train_dataset')\n",
        "shutil.copytree(val_dataset_to_copy_paths[0], 'val_dataset')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "79IvO4sQ3qW6",
        "outputId": "85372af4-fb25-4c8b-f6e3-735f76e59dba"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'val_dataset'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etqFheQknp3m",
        "outputId": "3ad0c731-a3bd-4f96-9fbc-1a903cf9037e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start Here"
      ],
      "metadata": {
        "id": "ic2wyNbv7tJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import outer_realm as otr\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dense, Conv1D, LSTM, \\\n",
        "MaxPooling1D, Flatten"
      ],
      "metadata": {
        "id": "fa-sAjGx8SnB"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "tKLQTg9kEiDh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recommended: Put all of your training tfrecords in ```train_dataset``` folder and all of your validation tfrecords in ```val_dataset``` folder. Warning: Your dataset must be in a flat hierarchy (no folder inside the dataset folder)."
      ],
      "metadata": {
        "id": "9USf3VYcLB3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_lists = [f'train_dataset/{i}' for i in os.listdir('train_dataset')]\n",
        "train_dataset = otr.initium.reader_get_data_and_epicenter(train_dataset_lists, True)\n",
        "\n",
        "val_dataset_lists = [f'val_dataset/{i}' for i in os.listdir('val_dataset')]\n",
        "val_dataset = otr.initium.reader_get_data_and_epicenter(val_dataset_lists, True)"
      ],
      "metadata": {
        "id": "Z6hpYS_l1nVA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Your Model"
      ],
      "metadata": {
        "id": "aOwkXedQEr71"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define your model here."
      ],
      "metadata": {
        "id": "sMa6VR-hLYF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.layers.Input(shape=(6400, 3))\n",
        "x = Conv1D(64, kernel_size=3, strides=1, padding='same', activation='relu')(inputs)\n",
        "\n",
        "for _ in range(2):\n",
        "  x = Conv1D(64, kernel_size=3, strides=1, padding='same', activation='relu')(x)\n",
        "  x = tf.keras.layers.MaxPooling1D(pool_size=3, strides=2)(x)\n",
        "\n",
        "x = tf.keras.layers.Conv1D(128, kernel_size=3, strides=1, padding='same', activation='relu')(x)\n",
        "x = tf.keras.layers.MaxPooling1D(pool_size=3, strides=2)(x)\n",
        "\n",
        "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(x)\n",
        "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(x)\n",
        "\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "outputs = tf.keras.layers.Dense(1)(x)\n",
        "\n",
        "proposed_model = tf.keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "1TuJxZi6EtT_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Call Apex Module"
      ],
      "metadata": {
        "id": "h7VBXqmTGCF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import outer_realm as otr\n",
        "import sys\n",
        "import os"
      ],
      "metadata": {
        "id": "sCw52x1UWtbA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configure Apex Module. I think the following arguments are straightforward enough to understand. No further explanation is required. Info: I have created an auto-checker for model compatibility and dataset compatibility. An error will be returned if any incompatibilities occur."
      ],
      "metadata": {
        "id": "5FB7lIpaAmZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "apex = otr.Apex(training_dataset=train_dataset,\n",
        "                validation_dataset=val_dataset,\n",
        "                window_length=6400,\n",
        "                channel_size=3,\n",
        "                batch_size=365,\n",
        "                model=proposed_model,\n",
        "                epoch=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioYoQ9aHZtnF",
        "outputId": "9e56eabf-ee9a-41ae-f52c-0da9372a1e5f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please wait. Checking model compability.\n",
            "Done! Your model is compatible.\n",
            "Please wait. Checking dataset compability.\n",
            "Done! Your dataset is compatible.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We assign the optimizers."
      ],
      "metadata": {
        "id": "fzavLeW7Aw_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "apex.update_optimizer(tf.keras.optimizers.Adam(learning_rate=1e-4))"
      ],
      "metadata": {
        "id": "_JJrCnOt7FgG"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the following code to train your model. Each time you train, an ```ApexTrainer``` object is created and a new training session ID is generated. You can see your models and its metadata (epoch logs) in the folder that is named based on your training session id."
      ],
      "metadata": {
        "id": "pwf689i3KTct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "if calculate_r2_per_epoch is false, the validation system won't calcualte R2 score\n",
        "if save_model_per_epoch is false, the model won't be saved per epoch\n",
        "(only be saved at the end of the training)\n",
        "'''\n",
        "apex.train(save_model_per_epoch=True, calculate_r2_per_epoch=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfearEuSN6Cv",
        "outputId": "b58007a7-f60e-4674-e2d4-b1eed357f78a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your training session ID: 91f9c40c-6b54-4e1a-a1ed-e9a4a6f0ec10.\n",
            "All training logs and model will automatically be saved in 91f9c40c-6b54-4e1a-a1ed-e9a4a6f0ec10 folder.\n",
            "\n",
            "Entering training stage now.\n",
            "Note: Proper progress bar appears at the second epoch.\n",
            "\n",
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "|                              | [02:11<00:00] Batch 211/211 | Training Loss: 4014.9402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 16882.6504\n",
            "Validation R2: 0.4521%\n",
            "\n",
            "Epoch 2/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "|██████████████████████████████| [02:03<00:00] Batch 211/212 | Training Loss: 4151.3291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 16540.0430\n",
            "Validation R2: 0.4662%\n",
            "\n",
            "Epoch 3/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "|██████████████████████████████| [02:03<00:00] Batch 211/212 | Training Loss: 4130.7891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 16098.1660\n",
            "Validation R2: 0.4749%\n",
            "\n",
            "Closed training session, Apex Trainer is freed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also update your previously assigned configuration."
      ],
      "metadata": {
        "id": "7vy1oC26KoxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "apex.update_epoch(5)"
      ],
      "metadata": {
        "id": "WaWyOk4fF6EH"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's retrai again. This time we are training with 5 epochs."
      ],
      "metadata": {
        "id": "cEDDL6o0KzeG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "apex.train(save_model_per_epoch=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7V92dce0KUh",
        "outputId": "46cbb95f-5a64-4191-972b-1b7ae94b8728"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your training session ID: 5dc539c3-573f-44c0-89c2-943c0cb5c04a.\n",
            "All training logs and model will automatically be saved in 5dc539c3-573f-44c0-89c2-943c0cb5c04a folder.\n",
            "\n",
            "Entering training stage now.\n",
            "Note: Proper progress bar appears at the second epoch.\n",
            "\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "|                              | [02:09<00:00] Batch 211/211 | Training Loss: 3953.6675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 15676.1729\n",
            "Validation R2: 0.4990%\n",
            "\n",
            "Epoch 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "|██████████████████████████████| [02:03<00:00] Batch 211/212 | Training Loss: 3878.1223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 15300.2305\n",
            "Validation R2: 0.5219%\n",
            "\n",
            "Epoch 3/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "|██████████████████████████████| [02:03<00:00] Batch 211/212 | Training Loss: 3101.9788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 14877.4561\n",
            "Validation R2: 0.5483%\n",
            "\n",
            "Epoch 4/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "|██████████████████████████████| [02:03<00:00] Batch 211/212 | Training Loss: 2639.1931\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 14541.0850\n",
            "Validation R2: 0.5801%\n",
            "\n",
            "Epoch 5/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "|██████████████████████████████| [02:03<00:00] Batch 211/212 | Training Loss: 2295.9592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 14209.8252\n",
            "Validation R2: 0.5970%\n",
            "\n",
            "Closed training session, Apex Trainer is freed.\n"
          ]
        }
      ]
    }
  ]
}